The first layer is a behavioral ML model, built using internal transaction and profile data. It captures each client’s normal financial activity and interaction style — such as transfer patterns, investment behavior, time-of-day activity, and risk indicators.

Any deviation — for example, a large fund transfer request from an unusual location or time — is flagged by the model as potentially risky.

This domain intelligence helps differentiate a legitimate client from an imposter who may have access to personal information but lacks behavioral alignment.

[Slide 6: Component 2 – LLM-Based Intent & Linguistic Signals]
Speaker:
The second component uses Large Language Models (LLMs) to analyze call transcripts.

We extract the intent of the conversation, along with subtle indicators of manipulation — such as urgency cues ("I need this now"), evasive behavior, inconsistent terminology, and attempts to bypass security.

These features are then fed into a lightweight ML model to generate a fraud intent risk score. This helps us detect even when the voice may match, but intentions don’t.

[Slide 7: Component 3 – Voice Analytics]**
Speaker:
Lastly, we add voice-layer intelligence — analyzing voice biometrics, tonality, stress levels, background noise patterns, and MFCC (Mel-Frequency Cepstral Coefficients) to assess speaker identity and emotional state.

This component allows for real-time bio-verification, emotion detection, and even cartel pattern recognition — identifying repeat offenders using similar tools or scripts across different calls.
